{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. N-grams\n",
    "\n",
    "The NLTK library contains some practical functions for n-gram extraction and frequency calculations. First, we will import NLTK again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install nltk\n",
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Unigram frequencies\n",
    "\n",
    "We will start with the n-grams by computing unigram frequencies, that is the frequencies of all word types in a corpus. We then print some words and their frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "unigram_freqs = nltk.FreqDist(tokenized)\n",
    "\n",
    "print('\"Emma\" occurs', unigram_freqs['Emma'], 'times.')\n",
    "print('\"handsome\" occurs', unigram_freqs['handsome'], 'times.')\n",
    "print('\"rich\" occurs', unigram_freqs['rich'], 'times.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we don't care what capitalization is used in a word, because we want to analyze all variants as the same word (for instance, \"same\" vs. \"Same\" vs. \"SAME\").\n",
    "\n",
    "To be able to unify all capitalization variants, we need to convert all words to the same format, for instance, lower-case. Lower-case means that all letters are converted to small letters. Let us retake the example with all words in lower-case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized = [w.lower() for w in nltk.corpus.gutenberg.words('austen-emma.txt')]\n",
    "unigram_freqs = nltk.FreqDist(tokenized)\n",
    "\n",
    "print('\"emma\" occurs', unigram_freqs['emma'], 'times.')\n",
    "print('\"handsome\" occurs', unigram_freqs['handsome'], 'times.')\n",
    "print('\"rich\" occurs', unigram_freqs['rich'], 'times.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the unigram frequencies changed and which ones did not? What might be the explanation?\n",
    "\n",
    "Next, let us find out which words are the most frequent ones in the corpus. Here we retrieve the 40 most frequent word forms and how many times they occur in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unigram_freqs.most_common(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot this information graphically as a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "n = 40  # number of most frequent words to plot\n",
    "\n",
    "words = [w for w, _ in unigram_freqs.most_common(n)]\n",
    "freqs = [f for _, f in unigram_freqs.most_common(n)]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(range(n), freqs)\n",
    "plt.xticks(range(n), words, rotation=90)\n",
    "plt.title(\"Unigrams\")\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if you change the number of words to plot?\n",
    "\n",
    "### 3.2 Bigram and trigram frequencies and beyond\n",
    "\n",
    "Similarly as for unigrams (that is, single words) it is possible to find the frequencies of bigrams, trigrams and higher-order n-grams. We start with bigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = nltk.bigrams(tokenized)\n",
    "bigram_freqs = nltk.FreqDist(bigrams)\n",
    "\n",
    "print('\"emma thought\" occurs', bigram_freqs['emma', 'thought'], 'times.')\n",
    "print('\"very handsome\" occurs', bigram_freqs['very', 'handsome'], 'times.')\n",
    "print('\"not rich\" occurs', bigram_freqs['not', 'rich'], 'times.')\n",
    "print()\n",
    "\n",
    "print(\"The 20 most common bigrams are:\", bigram_freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for trigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = nltk.trigrams(tokenized)\n",
    "trigram_freqs = nltk.FreqDist(trigrams)\n",
    "\n",
    "print('\"emma thought infinitely\" occurs', trigram_freqs['emma', 'thought', 'infinitely'], 'times.')\n",
    "print('\"rich and handsome\" occurs', trigram_freqs['rich', 'and', 'handsome'], 'times.')\n",
    "print()\n",
    "\n",
    "print(\"The 20 most common trigrams are:\", trigram_freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, generally for any order of n-grams. Here we use fourgrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourgrams = nltk.ngrams(tokenized, 4)\n",
    "fourgram_freqs = nltk.FreqDist(fourgrams)\n",
    "\n",
    "print('\"emma was particularly pleased\" occurs', fourgram_freqs['emma', 'was', 'particularly', 'pleased'], 'times.')\n",
    "print('\"she had often been\" occurs', fourgram_freqs['she', 'had', 'often', 'been'], 'times.')\n",
    "print()\n",
    "\n",
    "print(\"The 20 most common fourgrams are:\", fourgram_freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Conditional frequencies\n",
    "\n",
    "Typically, when we deal with n-grams we are not just interested in general n-gram frequencies in the corpus, but also interested in _conditional_ frequencies. Thinking about bigrams, for instance, we are interested in knowing which words follow a particular word and how many times that happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = nltk.bigrams(tokenized)\n",
    "\n",
    "conditional_bigram_dist = nltk.ConditionalFreqDist(bigrams)\n",
    "\n",
    "print('The 20 most common followers of \"emma\" are:', conditional_bigram_dist['emma'].most_common(20))\n",
    "print()\n",
    "\n",
    "print('The 20 most common followers of \"particularly\" are:', conditional_bigram_dist['particularly'].most_common(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also display this information in a table. The table shows us for every word at the beginning of the line how many times the words at the top of table occur after them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_words = [ 'emma', 'harriet', 'always', 'particularly', 'was', 'not' ]\n",
    "second_words = [ 'said', 'thought', 'admired', 'fond', 'you', 'good', 'handsome', 'horrible' ]\n",
    "\n",
    "conditional_bigram_dist.tabulate(conditional_bigram_dist, conditions=first_words, samples=second_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, we can see from the table that _\"not fond\"_ occurs twice in the corpus, and _\"particularly horrible\"_ does not occur at all in the corpus.\n",
    "\n",
    "It is now your turn to change the vocabulary that you want to analyze.\n",
    "\n",
    "After this, you can continue to Part 4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
