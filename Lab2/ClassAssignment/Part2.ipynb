{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Combining a lexicon with rules\n",
    "\n",
    "Next take a look at the examples of English verb inflection on page 51 of the slides of the second language technology lecture. The examples from the slides have been entered into the cell below. This is a morphological lexicon very similar to what you worked on in the first lab session. But there is an important difference. What is it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../morf-synt-2025/src\")\n",
    "from morpholexicon import *\n",
    "\n",
    "def root(state):\n",
    "    entry_a(\"\", verbstems, state)\n",
    "    \n",
    "def verbstems(state):\n",
    "    \"\"\" Sublexicon for English verb stems \"\"\"\n",
    "    entry_a(\"wait\", verblabel, state)\n",
    "    entry_a(\"jump\", verblabel, state)\n",
    "    entry_a(\"talk\", verblabel, state)\n",
    "    entry_a(\"look\", verblabel, state)\n",
    "\n",
    "    entry_a(\"bake\", verblabel, state)\n",
    "    entry_a(\"fake\", verblabel, state)\n",
    "    entry_a(\"pile\", verblabel, state)\n",
    "    entry_a(\"invite\", verblabel, state)\n",
    "\n",
    "    entry_a(\"try\", verblabel, state)\n",
    "    entry_a(\"apply\", verblabel, state)\n",
    "    entry_a(\"clarify\", verblabel, state)\n",
    "    entry_a(\"cry\", verblabel, state)\n",
    "    \n",
    "    entry_a(\"fix\", verblabel, state)\n",
    "    entry_a(\"match\", verblabel, state)\n",
    "    entry_a(\"crush\", verblabel, state)\n",
    "    entry_a(\"kiss\", verblabel, state)\n",
    "    \n",
    "        \n",
    "def verblabel(state):\n",
    "    \"\"\" Add +V to all verbs in their lexical form;\n",
    "        this is for stems without any alternation\n",
    "    \"\"\"\n",
    "    entry_t(\"+V\", \"^\", verbendings, state) # continue to endings\n",
    "    \n",
    "def verbendings(state):\n",
    "    \"\"\" Verb endings; this is for stems without any alternation \"\"\"\n",
    "    entry_t(\"+Inf\", \"\", None, state)\n",
    "    entry_t(\"+Pres3Sg\", \"s\", None, state)\n",
    "    entry_t(\"+Prog\", \"ing\", None, state)\n",
    "    entry_t(\"+Past\", \"ed\", None, state)\n",
    "\n",
    "# The main program starts here\n",
    "\n",
    "# First load the lexicon and tell Python that \"root\" is the starting point\n",
    "load_lexicon(root, None)\n",
    "\n",
    "# Generate all surface forms recognized by this lexicon\n",
    "generate_all()\n",
    "\n",
    "# End of program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lexicon will not work properly without replace rules. Page 35 of the slides of the second language technology lecture lists four rules. The two first ones have already been inserted to the code below. Your task is to enter the missing ones. Make sure that all surface forms are generated correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rules(input):\n",
    "    # Rule 1: Stem-final e is dropped in front of the vowels e and i\n",
    "    replace(r'e', r'', r'', r'\\^[ei]', input)\n",
    "\n",
    "    # Rule 2: An e is added in front of the ending s when preceded by a\n",
    "    # stem-final sibilant or y \n",
    "    replace(r'', r'e', r'(s|sh|ch|x|y)\\^', r's', input)\n",
    "\n",
    "    # Rule 3: A stem-final y becomes i in front of e\n",
    "    # TODO: Add your rule here!\n",
    "    \n",
    "    # Rule 4: The end-of-stem marker is dropped  \n",
    "    # TODO: Add your rule here!    \n",
    "    \n",
    "# The main program starts here\n",
    "\n",
    "# First load the lexicon and tell Python that \"root\" is the starting point\n",
    "# and that there are replace rules in a function called \"rules\"\n",
    "load_lexicon(root, rules)\n",
    "\n",
    "# Generate all surface forms recognized by this lexicon\n",
    "generate_all()\n",
    "\n",
    "# End of program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the program above, the lexicon is loaded in a different way than before. We now tell the system that the starting point is called \"root\" (as before), but additionally we have replace rules (which are in a function called \"rules\").\n",
    "\n",
    "Even though you now have a \"proper\" lexicon to go with your rules, it does not prevent you from using the _apply_ function as before, to help you understand the replacement steps that some specific surface form undergoes. You just need to type your input in the _intermediate_ format that your lexicon produces, that is, the format that is fed as input to the rules.\n",
    "\n",
    "For instance, for the word _cry_ in present tense third person, the plain lexicon without rules gives us _cry^s_. So, we can run the rules separately to see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply(rules, \"cry^s\", debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you managed to write rules that actually produce the desired surface form *cries*?\n",
    "\n",
    "Next, continue to Part 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
